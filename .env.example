# ============================================================================
# .env.example - Environment Configuration Template for Axion-Sat
# ============================================================================
#
# This file contains example environment variables for the Axion-Sat pipeline.
# Copy this file to `.env` and customize the values for your environment.
#
# SETUP INSTRUCTIONS:
# -------------------
# 1. Copy this file:
#    Windows (PowerShell):  Copy-Item .env.example .env
#    Linux/Mac (Bash):      cp .env.example .env
#
# 2. Edit `.env` with your specific values
#
# 3. The `.env` file is automatically loaded by:
#    - Python: python-dotenv package
#    - Docker: docker-compose
#
# IMPORTANT: Never commit `.env` to version control! It may contain secrets.
#            The `.env` file is already in .gitignore.
#
# ============================================================================

# ============================================================================
# STAC (SpatioTemporal Asset Catalog) API Endpoints
# ============================================================================
# These endpoints provide access to satellite imagery catalogs.

# AWS Earth Search - Public satellite data catalog (Sentinel-2, Landsat, etc.)
STAC_EARTHSEARCH=https://earth-search.aws.element84.com/v1

# Microsoft Planetary Computer - Curated geospatial data catalog
STAC_MPC=https://planetarycomputer.microsoft.com/api/stac/v1

# NASA LPCLOUD - Land Processes Distributed Active Archive Center
STAC_LPCLOUD=https://cmr.earthdata.nasa.gov/stac/LPCLOUD

# Default STAC endpoint to use (if not specified in code)
# Options: EARTHSEARCH, MPC, LPCLOUD
DEFAULT_STAC_PROVIDER=EARTHSEARCH

# ============================================================================
# Directory Paths
# ============================================================================
# Configure where data, cache, outputs, and model weights are stored.
# Use absolute paths for production, relative paths for development.

# Root directory for all data storage
# Windows example: C:/Users/YourName/Axion-Sat/data
# Linux example: /home/username/axion-sat/data
DATA_DIR=./data

# Cache directory for downloaded satellite tiles and intermediate files
# This can grow large (50+ GB), ensure sufficient disk space
CACHE_DIR=./cache

# Output directory for predictions, visualizations, and results
OUTPUT_DIR=./outputs

# Directory for trained model weights
WEIGHTS_DIR=./weights

# Temporary files directory (automatically cleaned)
TEMP_DIR=./temp

# Log files directory
LOG_DIR=./logs

# ============================================================================
# Quality Control (QC) Settings
# ============================================================================

# Minimum confidence score for accepting predictions (0.0 - 1.0)
# Predictions below this threshold are flagged as low-confidence
# Recommended: 0.75 for production, 0.60 for development/testing
QC_MIN_CONFIDENCE=0.75

# Maximum cloud coverage percentage (0 - 100)
# Satellite tiles with higher cloud coverage are rejected
QC_MAX_CLOUD_COVERAGE=30

# Minimum data completeness percentage (0 - 100)
# Reject AOIs where less than this % of pixels have valid data
QC_MIN_DATA_COMPLETENESS=90

# Flag predictions older than this many days as stale
QC_MAX_DATA_AGE_DAYS=30

# ============================================================================
# API Server Configuration
# ============================================================================

# Port for the inference/prediction API server
API_PORT=7860

# Host to bind the API server to
# Use 0.0.0.0 to allow external connections, 127.0.0.1 for localhost only
API_HOST=0.0.0.0

# API server log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
API_LOG_LEVEL=INFO

# Maximum number of concurrent API requests
API_MAX_WORKERS=4

# Request timeout in seconds
API_TIMEOUT=300

# Enable CORS (Cross-Origin Resource Sharing) for web frontends
API_ENABLE_CORS=true

# ============================================================================
# Authentication & Secrets
# ============================================================================
# IMPORTANT: Keep these secret! Never commit actual values to git.

# NASA Earthdata Login credentials (required for LPCLOUD STAC)
# Register at: https://urs.earthdata.nasa.gov/users/new
# EARTHDATA_USERNAME=your_username_here
# EARTHDATA_PASSWORD=your_password_here

# Microsoft Planetary Computer API key (optional, increases rate limits)
# Get key at: https://planetarycomputer.microsoft.com/account/request
# MPC_API_KEY=your_api_key_here

# AWS credentials (if using private S3 buckets)
# AWS_ACCESS_KEY_ID=your_access_key_here
# AWS_SECRET_ACCESS_KEY=your_secret_key_here
# AWS_REGION=us-west-2

# ============================================================================
# Model Configuration
# ============================================================================

# Default model version to use for inference
MODEL_VERSION=v2.1

# Model precision (float32, float16, bfloat16)
# float16 reduces memory usage, may slightly reduce accuracy
MODEL_PRECISION=float32

# Device for model inference (cuda, cpu, mps)
# Auto-detected if not specified
# MODEL_DEVICE=cuda

# Batch size for inference (adjust based on GPU memory)
INFERENCE_BATCH_SIZE=8

# Enable model warm-up on server start (loads model into memory)
MODEL_WARMUP=true

# ============================================================================
# Training Configuration
# ============================================================================

# Number of training epochs
TRAIN_EPOCHS=100

# Learning rate
TRAIN_LEARNING_RATE=0.001

# Batch size for training
TRAIN_BATCH_SIZE=16

# Number of data loader workers
TRAIN_NUM_WORKERS=4

# Enable mixed precision training (faster, less memory)
TRAIN_MIXED_PRECISION=true

# Save checkpoint every N epochs
TRAIN_CHECKPOINT_INTERVAL=10

# ============================================================================
# Logging & Monitoring
# ============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log format (json, text)
LOG_FORMAT=text

# Enable Weights & Biases (wandb) logging
WANDB_ENABLED=false
# WANDB_PROJECT=axion-sat
# WANDB_ENTITY=your_username

# Enable TensorBoard logging
TENSORBOARD_ENABLED=true
TENSORBOARD_LOG_DIR=./logs/tensorboard

# ============================================================================
# Resource Limits
# ============================================================================

# Maximum AOI area in square kilometers
MAX_AOI_AREA_KM2=10000

# Maximum concurrent download threads
MAX_DOWNLOAD_THREADS=5

# Maximum cache size in GB (oldest files deleted when exceeded)
MAX_CACHE_SIZE_GB=50

# Request rate limit (requests per minute)
RATE_LIMIT_RPM=60

# ============================================================================
# Feature Flags
# ============================================================================

# Enable experimental features
ENABLE_EXPERIMENTAL_FEATURES=false

# Enable debug mode (verbose logging, detailed error messages)
DEBUG_MODE=false

# Enable profiling (performance metrics)
ENABLE_PROFILING=false

# Skip GPU checks (useful for CPU-only testing)
SKIP_GPU_CHECKS=false

# ============================================================================
# Database Configuration (Optional)
# ============================================================================
# Uncomment and configure if using a database for request logging/caching

# DATABASE_URL=postgresql://user:password@localhost:5432/axion_sat
# DATABASE_POOL_SIZE=10
# DATABASE_MAX_OVERFLOW=20

# ============================================================================
# Redis Configuration (Optional)
# ============================================================================
# Uncomment if using Redis for caching

# REDIS_URL=redis://localhost:6379/0
# REDIS_PASSWORD=your_redis_password
# REDIS_TTL=3600

# ============================================================================
# Notification Settings (Optional)
# ============================================================================

# Email notifications for long-running jobs
# SMTP_HOST=smtp.gmail.com
# SMTP_PORT=587
# SMTP_USERNAME=your_email@gmail.com
# SMTP_PASSWORD=your_app_password
# NOTIFICATION_EMAIL=alerts@example.com

# Slack webhook for notifications
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# ============================================================================
# Development Settings
# ============================================================================

# Enable hot reload for development
DEV_HOT_RELOAD=false

# Use small subset of data for faster testing
DEV_USE_SMALL_DATASET=false

# Mock external API calls (for offline testing)
DEV_MOCK_EXTERNAL_APIS=false

# ============================================================================
# END OF CONFIGURATION
# ============================================================================

# REMINDER: After editing, restart any running services to apply changes.
# 
# Validate your configuration with:
#   python scripts/validate_env.py
#
# For more information, see: docs/configuration.md
